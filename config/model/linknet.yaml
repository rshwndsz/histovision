# LinkNet
# Paper: https://arxiv.org/abs/1707.03718
model:
  name: linknet
  class: segmentation_models_pytorch.Linknet
  params:
    # Name of classification model (without last dense layers) used as feature extractor to build segmentation model.
    encoder_name: resnet101
    # Number of stages used in decoder, larger depth - more features are generated.
    # e.g. for depth=3 encoder will generate list of features with following spatial shapes
    # [(H,W), (H/2, W/2), (H/4, W/4), (H/8, W/8)], so in general the deepest feature will have
    # spatial resolution (H/(2^depth), W/(2^depth)]
    encoder_depth: 5
    # One of [NULL => None (random initialization), imagenet => (pre-training on ImageNet)]
    encoder_weights: imagenet
    # If True, `BatchNormalisation` layer between `Conv2D` and `Activation` layers is used.
    # If 'inplace' InplaceABN will be used, allows to decrease memory consumption.
    # One of [True, False, 'inplace']
    decoder_use_batchnorm: True
    # Number of input channels for model, default is 3.
    in_channels: 3
    # Number of classes for output
    # output shape => [N C H W]
    classes: 2
    # Optional, final upsampling factor
    # default => 8 (for depth=3 to preserve input -> output spatial shape identity)
    activation: NULL
    # if specified model will have additional classification auxiliary output
    # build on top of encoder, supported params:
    #       - classes (int): number of classes
    #       - pooling (str): one of 'max', 'avg'. Default is 'avg'.
    #       - dropout (float): dropout factor in [0, 1)
    #       - activation (str): activation function to apply "sigmoid"/"softmax" (could be None to return logits)
    aux_params: NULL
